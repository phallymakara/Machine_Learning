{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82f0006c",
   "metadata": {},
   "source": [
    "# PT02 - Python for Data Science \n",
    "**AI Bootcamp - Instinct Institute**\n",
    "\n",
    "**Author:** MORK Mongkul"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffac745",
   "metadata": {},
   "source": [
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e802598",
   "metadata": {},
   "source": [
    "## Exercise 1: NumPy Array\n",
    "\n",
    "You are a **Data Scientist** preparing numerical data for a Machine Learning model.  \n",
    "Your task is to understand how NumPy stores and manipulates numerical data efficiently.\n",
    "\n",
    "**Task:**\n",
    "1. Import NumPy as `np`.\n",
    "2. Create a 1D NumPy array called `scores` containing:\n",
    "   - `[60, 65, 70, 78, 85]`\n",
    "3. Print the following properties:\n",
    "   - Shape\n",
    "   - Data type\n",
    "   - Number of dimensions\n",
    "4. Access:\n",
    "   - The first element\n",
    "   - The last element\n",
    "   - A slice containing the middle three values\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a31465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Do "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd88b501",
   "metadata": {},
   "source": [
    "## Exercise 2: Matrices and Spatial Slicing\n",
    "\n",
    "In Data Science, a 2D array often represents a dataset where **rows** are samples and **columns** are features. Mastering 2D slicing is essential for selecting specific data subsets.\n",
    "\n",
    "**Task:**\n",
    "1. Create a 4 × 4 NumPy array named `matrix` containing integers from 1 to 16.\n",
    "2. **Row/Column Access:**\n",
    "   - Print the entire second row.\n",
    "   - Print the entire third column.\n",
    "3. **Sub-matrix Extraction:**\n",
    "   - Use slicing to extract the \"center\" 2 × 2 square: `[[6, 7], [10, 11]]`.\n",
    "4. **Corner Extraction:**\n",
    "   - Extract the four corner elements using a single slicing operation (Hint: Use a **step** of 3).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf9c6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Do"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2253c876",
   "metadata": {},
   "source": [
    "## Exercise 4: Structural Transformations\n",
    "\n",
    "Data often arrives in a \"flat\" format. A Data Scientist must know how to change the shape of data without changing its values to fit the input requirements of AI models.\n",
    "\n",
    "**Task:**\n",
    "1. Create a 1D array of 12 elements from 10 to 120.\n",
    "2. **Reshape:** Transform this array into a 3 × 4 matrix.\n",
    "3. **Transpose:** Use the `.T` attribute to flip the matrix so that rows become columns.\n",
    "4. **Inferred Reshaping:** Use `reshape(-1, 2)` on the original array. Explain what the `-1` does.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd4962f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Do"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83210c1e",
   "metadata": {},
   "source": [
    "## Exercise 5: Feature Scaling (Min-Max Normalization)\n",
    "\n",
    "In Machine Learning, features often have different scales (e.g., Age 0-100 vs. Salary 20k-100k). We normalize data so that all features contribute equally to the model calculations.\n",
    "\n",
    "**Task:**\n",
    "1. Create a 10 × 3 matrix of random integers between 10 and 500.\n",
    "2. **Global Statistics:** Find the `min` and `max` values of the entire matrix.\n",
    "3. **Vectorized Operation:** Apply the Min-Max formula to scale the data between 0 and 1:\n",
    "\n",
    "$$X_{norm} = \\frac{X - X_{min}}{X_{max} - X_{min}}$$\n",
    "\n",
    "4. Print the first 5 rows of the normalized data to verify the values are between 0 and 1.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac65c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Do"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4128cad",
   "metadata": {},
   "source": [
    "## Exercise 7: One-Hot Encoding Simulation (Masking)\n",
    "\n",
    "ML models cannot process categorical labels (like \"Red\", \"Green\", \"Blue\") directly. We use boolean logic to convert categories into binary columns.\n",
    "\n",
    "**Task:**\n",
    "1. Create a 1D array `labels` with values: `[0, 1, 2, 0, 1, 2]`.\n",
    "2. **Boolean Masking:** Create three separate masks: `is_cat_0`, `is_cat_1`, and `is_cat_2` using equality comparisons.\n",
    "3. **Type Conversion:** Convert these boolean masks into integers (`0` and `1`) using the `.astype(int)` method.\n",
    "4. **Stacking:** Use `np.stack` or `np.column_stack` to combine them into a 6 × 3 matrix.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d9ca3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Do"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad4ae90",
   "metadata": {},
   "source": [
    "## Exercise 8: Mean Squared Error (MSE) Calculation\n",
    "\n",
    "In ML, we measure model performance by calculating the distance between predicted values ($\\hat{y}$) and actual values ($y$).\n",
    "\n",
    "**Task:**\n",
    "1. Create two 1D arrays of size 50: `y_true` and `y_pred` using random values.\n",
    "2. **Error Vector:** Calculate the difference (`y_true - y_pred`).\n",
    "3. **Aggregate:** Square the differences and find the average. Implement this formula using NumPy:\n",
    "\n",
    "$$MSE = \\frac{1}{n} \\sum_{i=1}^{n} (y_{\\text{true}} - y_{\\text{pred}})^2$$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07542378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Do "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc64792",
   "metadata": {},
   "source": [
    "## Exercise 9: Analysis of Titanic Survival Dataset\n",
    "\n",
    "In this comprehensive exercise, you will act as a **Data Analyst**. You have been handed the passenger manifest of the HMS Titanic. Your goal is to load, clean, and analyze the data to find patterns in survival rates.\n",
    "\n",
    "### Task 1: Load and Explore the Data\n",
    "\n",
    "1. Import `pandas` as `pd`.\n",
    "2. Load the dataset from the official bootcamp URL:  \n",
    "   `https://raw.githubusercontent.com/MorkMongkul/AI-Bootcamp-Instinct/main/Data/Titanic-Dataset.csv`\n",
    "3. Display the first 10 rows and use `df.info()` to identify which columns contain **NaN** (missing) values.\n",
    "4. Use `df.describe()` to find the average `Age` and the maximum `Fare` paid by a passenger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02759a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Do "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770b3d27",
   "metadata": {},
   "source": [
    "### Task 2: Data Cleaning\n",
    "\n",
    "1. Fill the missing values in the `Age` column with the **median** age of the dataset to avoid losing data.\n",
    "2. Remove the `Cabin` column entirely, as it contains too many missing values to be useful for AI.\n",
    "3. Convert the `Sex` column from strings to integers: change `\"male\"` to `0` and `\"female\"` to `1` using the `.map()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c769b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Do "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7fb833",
   "metadata": {},
   "source": [
    "### Task 3: Filtering\n",
    "\n",
    "1. Create a new DataFrame called `first_class_survivors` containing only passengers who were in `Pclass` 1 and had a `Survived` status of 1.\n",
    "2. Use the `.query()` method to find all passengers older than 70 years. How many are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61e65fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Do "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff1bbb9",
   "metadata": {},
   "source": [
    "### Task 4: Aggregation\n",
    "\n",
    "1. Group the data by `Pclass` and calculate the **mean** survival rate for each class.\n",
    "2. Use `value_counts()` on the `Embarked` column to determine which port (C, Q, or S) had the highest number of departures.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c302cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Do "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a93a680",
   "metadata": {},
   "source": [
    "## Exercise 12: Telcom Customer Churn Case Study\n",
    "\n",
    "In this exercise, you will follow the workflow used by Data Scientists to analyze customer retention. Your goal is to move from raw data to business insights using Pandas, Matplotlib, and Seaborn.\n",
    "\n",
    "### Task 1: Data Loading and Preprocessing\n",
    "\n",
    "1. Import `pandas`, `matplotlib.pyplot`, and `seaborn`.\n",
    "2. Load the dataset URL:  \n",
    "   `https://raw.githubusercontent.com/MorkMongkul/AI-Bootcamp-Instinct/main/Data/Telco-Customer-Churn.csv`\n",
    "3. **Handling the ID:** The `customerID` column is unique to every row and provides no statistical value. Drop it from your DataFrame.\n",
    "4. **Data Type Correction:** The `TotalCharges` column is stored as a string but should be numeric. Use `pd.to_numeric(errors='coerce')` to convert it.\n",
    "5. **Handling Nulls:** After the conversion, identify the missing values in `TotalCharges` and fill them with the median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f494aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Do "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2bf5078",
   "metadata": {},
   "source": [
    "### Task 2: Exploratory Data Analysis (Categorical)\n",
    "\n",
    "1. **Gender and Seniority:** Use `sns.countplot()` to visualize the distribution of `gender` and `SeniorCitizen`.\n",
    "2. **Contract and Payment:** Create count plots for `Contract` and `PaymentMethod`. Which categories are the most common?\n",
    "3. **Churn Distribution:** Visualize the `Churn` column. Calculate the exact percentage of customers who have left the company."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698f700d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Do "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1137329d",
   "metadata": {},
   "source": [
    "### Task 3: Feature Engineering and Pattern Analysis\n",
    "\n",
    "1. **Tenure Binning:** Create a new column `tenure_group` to group the `tenure` column into years (e.g., 0-12 months, 12-24 months, etc.) or categories (Short, Medium, Long term).\n",
    "2. **Service Analysis:** Create a visualization that shows the churn rate for different `InternetService` types (DSL, Fiber optic, No).\n",
    "3. **Contract Impact:** Use `sns.countplot(x='Contract', hue='Churn')` to determine which contract type has the highest churn frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a52587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Do"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf78f632",
   "metadata": {},
   "source": [
    "### Task 4: Numerical Analysis and Relationships\n",
    "\n",
    "1. **Monthly Charges:** Use `sns.kdeplot()` to compare the distribution of `MonthlyCharges` for customers who churned vs. those who stayed.\n",
    "2. **Tenure vs Churn:** Use `sns.boxplot(x='Churn', y='tenure')` to visualize the median time (months) it takes for a customer to churn.\n",
    "3. **Total Spend:** Use `sns.scatterplot(x='tenure', y='TotalCharges', hue='Churn')` to see the relationship between length of stay and total revenue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8158a000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Do "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5df124",
   "metadata": {},
   "source": [
    "### Task 5: Correlation Analysis\n",
    "\n",
    "1. **Encoding:** Convert the `Churn` column to numeric values (`Yes=1, No=0`) and use `pd.get_dummies()` to convert other categorical variables into dummy variables.\n",
    "2. **Heatmap:** Generate a correlation matrix for the entire dataset.\n",
    "3. **Visualization:** Plot the correlation matrix using `sns.heatmap()` with `annot=True`.\n",
    "4. **Insight:** Identify the top 3 features that have the strongest positive or negative correlation with `Churn`.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bde59dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Do "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
